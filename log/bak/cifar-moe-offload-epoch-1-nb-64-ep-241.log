[2022-09-10 22:08:24,074] [WARNING] [runner.py:178:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2022-09-10 22:08:24,207] [INFO] [runner.py:504:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 cifar10_deepspeed.py --log-interval 100 --deepspeed --deepspeed_config ds_config_offload.json --moe --ep-world-size 4 --num-experts 1 --top-k 1 --noisy-gate-policy RSample --moe-param-group
[2022-09-10 22:08:25,715] [INFO] [launch.py:136:main] WORLD INFO DICT: {'localhost': [0, 1]}
[2022-09-10 22:08:25,715] [INFO] [launch.py:143:main] nnodes=1, num_local_procs=2, node_rank=0
[2022-09-10 22:08:25,716] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2022-09-10 22:08:25,716] [INFO] [launch.py:156:main] dist_world_size=2
[2022-09-10 22:08:25,716] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0,1
[2022-09-10 22:08:27,437] [INFO] [comm.py:635:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[W ProcessGroupNCCL.cpp:1569] Rank 1 using best-guess GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.
Files already downloaded and verified
[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
plane   dog   dog  bird
Traceback (most recent call last):
  File "cifar10_deepspeed.py", line 228, in <module>
    net = Net()
  File "cifar10_deepspeed.py", line 203, in __init__
    noisy_gate_policy=args.noisy_gate_policy))
  File "/home/cc/.local/lib/python3.6/site-packages/deepspeed/moe/layer.py", line 54, in __init__
    assert num_experts % ep_size == 0, f"Number of experts ({num_experts}) should be divisible by expert parallel size ({ep_size})"
AssertionError: Number of experts (1) should be divisible by expert parallel size (4)
[2022-09-10 22:08:35,759] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 56907
[2022-09-10 22:08:35,759] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 56908
[2022-09-10 22:08:36,070] [ERROR] [launch.py:292:sigkill_handler] ['/usr/bin/python3', '-u', 'cifar10_deepspeed.py', '--local_rank=1', '--log-interval', '100', '--deepspeed', '--deepspeed_config', 'ds_config_offload.json', '--moe', '--ep-world-size', '4', '--num-experts', '1', '--top-k', '1', '--noisy-gate-policy', 'RSample', '--moe-param-group'] exits with return code = 1
